version: '3'

x-spark-common: &spark-common
  build:
    context: .
    dockerfile: Dockerfile.spark  
  volumes:
    - ./jobs:/opt/bitnami/spark/jobs
  networks:
    - flights

x-airflow-common: &airflow-common
  build:
    context: .
    dockerfile: Dockerfile.airflow
  env_file:
    - airflow.env
  volumes:
    - ./config:/opt/airflow/config
    - ./dags:/opt/airflow/dags
    - ./requirements.txt:/opt/airflow/requirements.txt
    - ./pytest.ini:/opt/airflow/pytest.ini
    - ./data/flight_extraction:/opt/airflow/data/flight_extraction
    - ./data/flight_detail_extraction:/opt/airflow/data/flight_detail_extraction
    - ./data/flight_history_extraction:/opt/airflow/data/flight_history_extraction
    - ./data/airline_extraction:/opt/airflow/data/airline_extraction
    - ./data/airport_extraction:/opt/airflow/data/airport_extraction
    - ./data/cleanned:/opt/airflow/data/cleanned
    - ./data/current_flight/nb_per_company:/opt/airflow/data/current_flight/nb_per_company
    - ./data/current_flight/regionnal_flight:/opt/airflow/data/current_flight/regionnal_flight
    - ./data/current_flight/longgest_flight_by_time:/opt/airflow/data/current_flight/longgest_flight_by_time
    - ./data/current_flight/longgest_flight_by_distance:/opt/airflow/data/current_flight/longgest_flight_by_distance
    - ./data/current_flight/aircraft_company_flights:/opt/airflow/data/current_flight/aircraft_company_flights
    - ./data/avg_distance_flight_by_continent:/opt/airflow/data/avg_distance_flight_by_continent
    - ./data/aircraft_model:/opt/airflow/data/aircraft_model
    - ./data/in_out_flights:/opt/airflow/data/in_out_flights
    - ./etls:/opt/airflow/etls
    - ./tests:/opt/airflow/tests
    - ./utils:/opt/airflow/utils
    - ./logs:/opt/airflow/logs
  depends_on:
    - postgres
  networks:
    - flights

services:
  spark-master:
    <<: *spark-common
    command: bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "9090:8080"
      - "7077:7077"

  spark-worker-1:
    <<: *spark-common
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_MASTER_URL: spark://spark-master:7077

  spark-worker-2:
    <<: *spark-common
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_MASTER_URL: spark://spark-master:7077

  spark-worker-3:
    <<: *spark-common
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_MASTER_URL: spark://spark-master:7077

  postgres:
    image: postgres:14.0
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5433:5433"  # Changer le port externe Ã  5433
    networks:
      - flights

  webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8080:8080"
    depends_on:
      - scheduler

  scheduler:
    <<: *airflow-common
    command: bash -c "airflow db init && airflow users create --username admin --firstname chris --lastname sive --role Admin --email chris.120@hotmail.fr --password admin && airflow scheduler"
  
  # superset:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile.superset
  #   container_name: superset
  #   ports:
  #     - "8088:8088"
  #   environment:
  #     - SUPERSET_LOAD_EXAMPLES=no
  #     - POSTGRES_DB=superset
  #     - POSTGRES_USER=superset
  #     - POSTGRES_PASSWORD=password
  #     - POSTGRES_HOST=superset-db
  #     - POSTGRES_PORT=5432
  #   depends_on:
  #     - superset-db
  #   networks:
  #     - superset

  # superset-db:
  #   image: postgres:14.0
  #   container_name: superset-db
  #   environment:
  #     - POSTGRES_DB=superset
  #     - POSTGRES_USER=superset
  #     - POSTGRES_PASSWORD=password
  #   volumes:
  #     - ./postgres-data:/var/lib/postgresql/data
  #   networks:
  #     - superset
      
  # prometheus:
  #   image: prom/prometheus
  #   volumes:
  #     - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
  #   ports:
  #     - "9091:9090"
  #   command:
  #     - '--config.file=/etc/prometheus/prometheus.yml'
  #   networks:
  #     - flights

  # grafana:
  #   image: grafana/grafana
  #   ports:
  #     - "3000:3000"
  #   volumes:
  #     - ./grafana:/var/lib/grafana
  #   depends_on:
  #     - prometheus
  #   networks:
  #     - flights

  # elasticsearch:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:7.13.4
  #   environment:
  #     - discovery.type=single-node
  #     - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
  #   ports:
  #     - "9200:9200"
  #   networks:
  #     - flights

  # logstash:
  #   image: docker.elastic.co/logstash/logstash:7.13.4
  #   volumes:
  #     - ./config/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
  #   depends_on:
  #     - elasticsearch
  #   networks:
  #     - flights
      
networks:
  flights:
  superset: